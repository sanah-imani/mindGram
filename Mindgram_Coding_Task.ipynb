{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mindgram Coding Task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47b111ab0d8f4f2aa6bf3cc917ad54e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d2ce72bfd8894550b8c0e07a62898c48",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7bbf3a620f374b49bcf89b55a09873ee",
              "IPY_MODEL_d1d19bc1c4d34c038794a2c59cb75540",
              "IPY_MODEL_518869256c4e4488b048fd89a97cb1ac"
            ]
          }
        },
        "d2ce72bfd8894550b8c0e07a62898c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bbf3a620f374b49bcf89b55a09873ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54011978557a4b1fb5819446997e3606",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07c4bee7e1ce454cacfdd1a50eaed3de"
          }
        },
        "d1d19bc1c4d34c038794a2c59cb75540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a8bbdd0aaf944d7bb73ec72ce4b478d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 74,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 74,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb603951b26d42688123ad3d974db95e"
          }
        },
        "518869256c4e4488b048fd89a97cb1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5409933f53244a9fa12e918d7562067e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 74/74 [01:12&lt;00:00,  1.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c71470ecf209457296cfa788c74bc121"
          }
        },
        "54011978557a4b1fb5819446997e3606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07c4bee7e1ce454cacfdd1a50eaed3de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a8bbdd0aaf944d7bb73ec72ce4b478d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb603951b26d42688123ad3d974db95e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5409933f53244a9fa12e918d7562067e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c71470ecf209457296cfa788c74bc121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.10.1 --quiet"
      ],
      "metadata": {
        "id": "i38pdAtSYAqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "tNIx9MgRhfdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"torchmetrics<0.7\""
      ],
      "metadata": {
        "id": "TkA2F-O3jKyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing gpu prescence\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "kf8Q8qncErkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tKpM4f7N_2SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QgIIgg2BFGJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "#pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast as BertTokenizer, BertModel as BM, AdamW as Adam\n",
        "\n",
        "#pytorch scheduler\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "#pytorch lightning - lots of features like model checkpoints, logging, metrics, etc\n",
        "import transformers\n",
        "import pytorch_lightning as pl\n",
        "#from torchmetrics import Accuracy\n",
        "from torchmetrics.functional import auroc \n",
        "#going to create a confusion matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from seqeval.metrics import classification_report as classification_report_seqeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IMP Params\n",
        "EPOCHS = 4\n",
        "BATCH_SIZE = 16\n",
        "MAX_TOKEN_NUM = 256"
      ],
      "metadata": {
        "id": "7HubajTRMRcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a training and testing dataset\n",
        "labeledFile = open('news_blobs_labeled.json')\n",
        "testingFile = open('news_blobs_test.json')\n",
        "#loading data from file\n",
        "labeledData = json.load(labeledFile)\n",
        "testingData = json.load(testingFile)\n",
        "labeledSize = len(labeledData)\n",
        "testingSize = len(testingData)\n",
        "print(\"Labeled data shape:\", len(labeledData))\n",
        "print(\"Testing data shape: \", len(testingData))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfBkFg9XC28P",
        "outputId": "7363cb53-605b-481c-87d2-ec574da9b7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeled data shape: 738\n",
            "Testing data shape:  81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conversion into dataframes - training + validation\n",
        "tdLabels = pd.DataFrame([labeledData[i]['labels'] for i in range(labeledSize)])\n",
        "tdText= pd.DataFrame([{\"text\": labeledData[i]['text']} for i in range(labeledSize)])\n",
        "totaldf = pd.concat([tdText, tdLabels], axis=1)\n",
        "totaldf.head()"
      ],
      "metadata": {
        "id": "Mi8UDQZlK1M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLUMNS = totaldf.columns.tolist()[1:]\n",
        "COLUMNS"
      ],
      "metadata": {
        "id": "pQ17KLQYHwAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use of validation data will help with accuracy prediction \n",
        "from sklearn.model_selection import train_test_split\n",
        "traindf, valdf = train_test_split(totaldf, test_size=0.1)\n",
        "traindf.shape, valdf.shape"
      ],
      "metadata": {
        "id": "LFE1ysiIr44Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what is the distribution of the labeled data given\n",
        "samples = dict()\n",
        "for col in COLUMNS:\n",
        "  samples[col] = sum(totaldf[col])\n",
        "samples"
      ],
      "metadata": {
        "id": "xD_g37FMXvS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we may want pre-process the training dataset to counter the imbalance \n",
        "other_df = traindf[traindf[\"OTHER\"] == 1]\n",
        "other_df.head()"
      ],
      "metadata": {
        "id": "uXkqHiFgYvNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reduce the number of clinical trial alone ones\n",
        "SELECT_COLUMNS = ['REGULATORY', 'COLLAB', \"FINANCING\", \"PRESENTATION\"]\n",
        "clinic_df = traindf[traindf['CLINICAL_TRIAL'] == 1]\n",
        "clinic_df = clinic_df[clinic_df[SELECT_COLUMNS ].sum(axis = 1) == 0]\n",
        "clinic_df.head()"
      ],
      "metadata": {
        "id": "yae4JPWc0zKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training samples without the other label\n",
        "non_other_df = traindf[traindf[SELECT_COLUMNS ].sum(axis = 1) > 0]\n",
        "non_other_df.head(40)"
      ],
      "metadata": {
        "id": "aXhezn4JxFVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample accordingly to avoid biased training data\n",
        "print(other_df.shape, non_other_df.shape)\n",
        "minSize = min(other_df.shape[0], non_other_df.shape[0])\n",
        "traindf = pd.concat([non_other_df.sample(minSize), clinic_df.sample(50), other_df.sample(minSize)])"
      ],
      "metadata": {
        "id": "kSww4KnjxxvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the \"other\" column\n",
        "if \"OTHER\" in traindf.columns:\n",
        "  traindf = traindf.drop(\"OTHER\", 1)\n",
        "if \"OTHER\" in valdf.columns:\n",
        "  valdf = valdf.drop(\"OTHER\", 1)\n",
        "traindf.head()"
      ],
      "metadata": {
        "id": "LeiY--wPM67H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindf.head(50)"
      ],
      "metadata": {
        "id": "Hi1ulEcN5Scm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labels with \"other\"\n",
        "if \"OTHER\" in COLUMNS:\n",
        "    COLUMNS.remove(\"OTHER\")"
      ],
      "metadata": {
        "id": "mvrKCoKKdRv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conversion into dataframes - testing  \n",
        "testdf = pd.DataFrame([{\"text\": testingData[i]['text']} for i in range(testingSize)])\n",
        "testdf.head()"
      ],
      "metadata": {
        "id": "QQfj4E-3ZhFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initial look into the data\n",
        "print('Research text sample:', traindf['text'].iloc[0])"
      ],
      "metadata": {
        "id": "AR0lQ-wiKVns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clean titles\n",
        "for i in range(traindf.shape[0]):\n",
        "  traindf['text'].iloc[i].strip().lower()\n",
        "for i in range(valdf.shape[0]):\n",
        "  valdf['text'].iloc[i].strip().lower()\n",
        "for i in range(testingSize):\n",
        "  testdf['text'].iloc[i].strip().lower()"
      ],
      "metadata": {
        "id": "Z3jEOtlbK92G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#before processing data, create tokenizer instance\n",
        "'''\n",
        "BERT is a transformers model pretrained on a large corpus of English data in a self-supervised fashion.\n",
        "'''\n",
        "BERT_MODEL_NAME_0 = 'bert-base-cased'\n",
        "BERT_MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
      ],
      "metadata": {
        "id": "xQS4jSZDI-t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a pytorch dataset class\n",
        "class MedicalDataset(Dataset):\n",
        "  def __init__(self, data,  tokenizer):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.dataLen = len(self.data)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.dataLen\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    data_row = self.data.iloc[index]\n",
        "\n",
        "    medical_text = data_row['text']\n",
        "    labels = data_row[COLUMNS]\n",
        "\n",
        "    #creating an encoding \n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      medical_text,\n",
        "      add_special_tokens=True,\n",
        "      max_length=MAX_TOKEN_NUM,\n",
        "      return_token_type_ids=False,\n",
        "      padding=\"max_length\",\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return dict(\n",
        "      medical_text=medical_text,\n",
        "      input_ids=encoding[\"input_ids\"].flatten(),\n",
        "      attention_mask=encoding[\"attention_mask\"].flatten(),\n",
        "      labels=torch.FloatTensor(labels)\n",
        "    )"
      ],
      "metadata": {
        "id": "p--sHxXuGfDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalTextDataModule(pl.LightningDataModule):\n",
        "  #three datasets - training, testing, validation dataset\n",
        "  def __init__(self, train_df, val_df, test_df, tokenizer):\n",
        "    super().__init__()\n",
        "    self.train_df = train_df\n",
        "    self.test_df = test_df\n",
        "    self.val_df = val_df\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  #datasets setup - training, validation, testing  \n",
        "  def setup(self, stage=None):\n",
        "    self.train_dataset = MedicalDataset(\n",
        "      self.train_df,\n",
        "      self.tokenizer\n",
        "    )\n",
        "    self.val_dataset = MedicalDataset(\n",
        "        self.val_df, \n",
        "        self.tokenizer)\n",
        "    \n",
        "    self.test_dataset = MedicalDataset(\n",
        "      self.test_df,\n",
        "      self.tokenizer\n",
        "    )\n",
        "\n",
        "  #The num_workers attribute tells the data loader instance how many sub-processes to use for data loading.\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.train_dataset,\n",
        "      batch_size= BATCH_SIZE,\n",
        "      shuffle=True,\n",
        "      num_workers=2)\n",
        "    \n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.val_dataset,\n",
        "      batch_size= BATCH_SIZE,\n",
        "      shuffle=True,\n",
        "      num_workers=2)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.test_dataset,\n",
        "      batch_size=BATCH_SIZE,\n",
        "      num_workers=2)"
      ],
      "metadata": {
        "id": "Wxo2wyx0Jwd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load a pre-trained BERT model - transfer learning\n",
        "bert_model = BM.from_pretrained(BERT_MODEL_NAME, return_dict=True)"
      ],
      "metadata": {
        "id": "krtPueuIGbw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a data module with all datasets in place\n",
        "med_data_module = MedicalTextDataModule(traindf, valdf, valdf, tokenizer)"
      ],
      "metadata": {
        "id": "syU0FMTDLXAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalTextLabelClassifier(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, bert_model, n_classes, criterion, n_training_steps=None):\n",
        "    super().__init__()\n",
        "    #pre-trained bert_model\n",
        "    self.bert = bert_model\n",
        "    #classifier linear model\n",
        "    self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "    #how many times step is called\n",
        "    self.n_training_steps = n_training_steps\n",
        "    self.criterion = criterion\n",
        "\n",
        "  #the forward function enables us to define how the model goes from input to output\n",
        "  def forward(self, input_ids, attention_mask, labels=None):\n",
        "    output = self.bert(input_ids, attention_mask=attention_mask)\n",
        "    #last layer to a classifier output\n",
        "    output = self.classifier(output.pooler_output)\n",
        "    #our activation function\n",
        "    output = torch.sigmoid(output)    \n",
        "    loss = 0\n",
        "    if labels is not None:\n",
        "        loss = self.criterion(output, labels)\n",
        "    return loss, output\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    #attention masks - binary masks to hide the padded indices\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    if batch_idx % 5000:\n",
        "      print({\"loss\": loss})\n",
        "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    return loss\n",
        "\n",
        "  def training_epoch_end(self, outputs):\n",
        "    #collecting the labels and predictions from the output\n",
        "    labels = []\n",
        "    predictions = []\n",
        "    for output in outputs:\n",
        "      for output_labels in output[\"labels\"].detach().cpu():\n",
        "        labels.append(output_labels)\n",
        "      for output_predictions in output[\"predictions\"].detach().cpu():\n",
        "        predictions.append(output_predictions)\n",
        "\n",
        "    labels = torch.stack(labels).int()\n",
        "    predictions = torch.stack(predictions)\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "\n",
        "    optimizer = Adam(self.parameters(), lr=1e-5)\n",
        "\n",
        "    #the scheduler enables us to adjust the learning rate\n",
        "    scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "    return dict(\n",
        "      optimizer=optimizer,\n",
        "      lr_scheduler=dict(\n",
        "        scheduler=scheduler,\n",
        "        interval='step'\n",
        "      )\n",
        "    )"
      ],
      "metadata": {
        "id": "WzC2skeYNTAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criterion - measuring the Binary Cross Entropy between the target and the input probabilities\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "gBIdQYT-bngV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "#calculating number of train steps\n",
        "total_training_steps = BATCH_SIZE * EPOCHS\n",
        "\n",
        "model = MedicalTextLabelClassifier(\n",
        "    bert_model,\n",
        "  n_classes=len(COLUMNS),\n",
        "  criterion = criterion,\n",
        "  n_training_steps=total_training_steps \n",
        ")\n",
        "\n",
        "#lightning module training configs\n",
        "trainer = pl.Trainer(\n",
        "  logger= None,\n",
        "  checkpoint_callback= None,\n",
        "  callbacks= None,\n",
        "  gpus=1,\n",
        "  max_epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx8MTPvueLqY",
        "outputId": "20904a88-1e1d-4d0a-89e6-6c8fd76ef9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clear memory\n",
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "IltyTwnWAQEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting \n",
        "trainer.fit(model, med_data_module)"
      ],
      "metadata": {
        "id": "4pl1GENcgtbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation mode\n",
        "model.eval()\n",
        "model.freeze()"
      ],
      "metadata": {
        "id": "GFSPIWQVQ4_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "trained_model = model.to(device)\n",
        "#evaluation\n",
        "val_dataset = MedicalDataset(valdf, tokenizer)\n",
        "\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "#wrap the iterable with tqdm\n",
        "for item in tqdm(val_dataset):\n",
        "  _, prediction = trained_model(\n",
        "    item[\"input_ids\"].unsqueeze(dim=0).to(device), \n",
        "    item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
        "  )\n",
        "  predictions.append(prediction.flatten())\n",
        "  labels.append(item[\"labels\"].int())\n",
        "\n",
        "predictions = torch.stack(predictions).detach().cpu()\n",
        "labels = torch.stack(labels).detach().cpu()"
      ],
      "metadata": {
        "id": "3U1QBpC0OJB2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "47b111ab0d8f4f2aa6bf3cc917ad54e0",
            "d2ce72bfd8894550b8c0e07a62898c48",
            "7bbf3a620f374b49bcf89b55a09873ee",
            "d1d19bc1c4d34c038794a2c59cb75540",
            "518869256c4e4488b048fd89a97cb1ac",
            "54011978557a4b1fb5819446997e3606",
            "07c4bee7e1ce454cacfdd1a50eaed3de",
            "7a8bbdd0aaf944d7bb73ec72ce4b478d",
            "bb603951b26d42688123ad3d974db95e",
            "5409933f53244a9fa12e918d7562067e",
            "c71470ecf209457296cfa788c74bc121"
          ]
        },
        "outputId": "47adcf8a-4825-438d-8aa0-12cca99297fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47b111ab0d8f4f2aa6bf3cc917ad54e0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/74 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUTOFF = 0.5\n",
        "#fscore, precision, recall, etc\n",
        "y_pred = predictions.numpy()\n",
        "\n",
        "#true labels, vs predictions - assigned an upper and lower bound\n",
        "y_true = labels.numpy()\n",
        "y_pred = np.where(y_pred >= CUTOFF, 1, 0)\n"
      ],
      "metadata": {
        "id": "_Y2sCRWBCR7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrices\n",
        "cm = multilabel_confusion_matrix(y_true, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "dMiIeT9LkILL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy\n",
        "accDict = dict()\n",
        "for i, label in enumerate(COLUMNS):\n",
        "  row = cm[i]\n",
        "  tp = row[0][0]\n",
        "  tn = row[1][1]\n",
        "  fp = row[0][1]\n",
        "  fn = row[1][0]\n",
        "  accDict[label] = ((tp+tn)/(tp+tn+fp+fn))\n",
        "accDict\n",
        "  "
      ],
      "metadata": {
        "id": "p4dxHEnFJAlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AUROC per label\")\n",
        "for i, name in enumerate(COLUMNS):\n",
        "  tag_auroc = auroc(predictions[:, i], labels[:, i], pos_label=1)\n",
        "  print(f\"{name}: {tag_auroc}\")"
      ],
      "metadata": {
        "id": "OkwRJEyhkG_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_encodings(text):\n",
        "  encoding = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_TOKEN_NUM,\n",
        "        return_token_type_ids=False,\n",
        "        padding=\"max_length\",\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "      )\n",
        "  return encoding"
      ],
      "metadata": {
        "id": "QpGVo2Pg0tE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing \n",
        "def run_tests(path):\n",
        "    results = []\n",
        "    resultsFilePath = path\n",
        "    for i in range(testingSize):\n",
        "      #extract the text of the test news blobs\n",
        "      test_text = testdf.iloc[i]['text']\n",
        "      #create an encoding\n",
        "      encoding = create_test_encodings(test_text)\n",
        "      #use our trained model\n",
        "      _, test_prediction = trained_model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\n",
        "      \n",
        "      test_prediction = test_prediction.flatten().numpy()\n",
        "      predDict = {}\n",
        "      for label, prediction in zip(COLUMNS, test_prediction):\n",
        "        if prediction < CUTOFF - 0.1:\n",
        "          predDict[label] = 0\n",
        "        else:\n",
        "          \n",
        "          predDict[label] = 1\n",
        "\n",
        "      sumVar = 0 \n",
        "      for label in predDict:\n",
        "          sumVar += predDict[label]\n",
        "      if sumVar == 0:\n",
        "        predDict[\"OTHER\"] = 1\n",
        "      else:\n",
        "        predDict[\"OTHER\"] = 0\n",
        "      predDict['text'] = test_text\n",
        "      results.append(predDict)\n",
        "\n",
        "    resultsDF = pd.DataFrame(results)  \n",
        "    resultsDF.to_csv(path, index=False)\n",
        "    return \n",
        "    "
      ],
      "metadata": {
        "id": "FJRk_rAnwla1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_tests(\"text_classification.csv\")"
      ],
      "metadata": {
        "id": "xLTcZWyH89EW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}