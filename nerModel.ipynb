{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nerModel.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bc01dc4dbb14e42b75b9b4ca9958dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d9d569dc06d47fb9338d5bfbc7519f2",
              "IPY_MODEL_c071788fc1d34772a37f70a32cc2ba4f",
              "IPY_MODEL_4a124102ff0e400b8f6946855f3c1e79"
            ],
            "layout": "IPY_MODEL_4a2b4a4dcc7b49d98ee83e17592ce3db"
          }
        },
        "9d9d569dc06d47fb9338d5bfbc7519f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86bc495937eb418ca400f4a11127b72d",
            "placeholder": "​",
            "style": "IPY_MODEL_0da097b99f35438ea6a45452a61b6fc2",
            "value": "Downloading: 100%"
          }
        },
        "c071788fc1d34772a37f70a32cc2ba4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50e3e0ad3b4d4fb791d57b043bc74c33",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f94ac64dfa8486799043b68c6849c7d",
            "value": 385
          }
        },
        "4a124102ff0e400b8f6946855f3c1e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_472257d6a7dd4a87822d0461a29d891e",
            "placeholder": "​",
            "style": "IPY_MODEL_0e9bb69d78d44825bf4ed012f7660b68",
            "value": " 385/385 [00:00&lt;00:00, 15.3kB/s]"
          }
        },
        "4a2b4a4dcc7b49d98ee83e17592ce3db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bc495937eb418ca400f4a11127b72d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da097b99f35438ea6a45452a61b6fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50e3e0ad3b4d4fb791d57b043bc74c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f94ac64dfa8486799043b68c6849c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "472257d6a7dd4a87822d0461a29d891e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9bb69d78d44825bf4ed012f7660b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae31a6e0895b4f2ea6cdc58b5522f9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78b08f8b56834207acb4c488f82802bf",
              "IPY_MODEL_7069bb568786420aa128d0166687c5fe",
              "IPY_MODEL_d27cd5f792a0454da845636f04a9d9ed"
            ],
            "layout": "IPY_MODEL_1158c085523d4de4941e2c338b2395a6"
          }
        },
        "78b08f8b56834207acb4c488f82802bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a6cb58292e24175a768cdfc87bd19d5",
            "placeholder": "​",
            "style": "IPY_MODEL_97c61e05d9c841fdb421bc64c5c9ff85",
            "value": "Downloading: 100%"
          }
        },
        "7069bb568786420aa128d0166687c5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7760a69dacab4d6ab28dbfd721371297",
            "max": 227845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed77830242b94f3fa0ea65f7e6acdcde",
            "value": 227845
          }
        },
        "d27cd5f792a0454da845636f04a9d9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1fd6b886c394094bba28ea647ea82ad",
            "placeholder": "​",
            "style": "IPY_MODEL_0052db101067490c9b746c2025f3a6a6",
            "value": " 228k/228k [00:00&lt;00:00, 809kB/s]"
          }
        },
        "1158c085523d4de4941e2c338b2395a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6cb58292e24175a768cdfc87bd19d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c61e05d9c841fdb421bc64c5c9ff85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7760a69dacab4d6ab28dbfd721371297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed77830242b94f3fa0ea65f7e6acdcde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1fd6b886c394094bba28ea647ea82ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0052db101067490c9b746c2025f3a6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kgCysjalJAy"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "@brief: After creating the “gold-standard” dataset, our task is to identify the most appropriate base language model that could be further fine-tuned on the dataset obtained in Step 1.\n",
        "\n",
        "Since our text corpus primarily consists of scientific texts in the biomedical domain, potential candidates for our choice of the base model include:\n",
        "\n",
        "BiomedNLP-PubMedBERT-base-uncased-abstract-full text\n",
        "SciBERT\n",
        "ElectraMed\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "RX_dxscbLyxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb16463e-7b16-456b-ee8b-717d554b8918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.3 MB/s \n",
            "\u001b[?25hCollecting typing-extensions>=4.0.0\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[K     |████████████████████████████████| 398 kB 74.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n",
            "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.63.0)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.5)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 76.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n",
            "Installing collected packages: typing-extensions, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, PyYAML, pytorch-lightning\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.0 torchmetrics-0.7.3 typing-extensions-4.1.1 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.10.1 --quiet"
      ],
      "metadata": {
        "id": "jClYVNziMsg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba16059-bf5b-417c-a921-c610db4452b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.8 MB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 73.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 55.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"torchmetrics<0.7\""
      ],
      "metadata": {
        "id": "IvjesZj4L0kH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b72fc01-7bd2-4e50-a219-7233d550cd30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics<0.7\n",
            "  Downloading torchmetrics-0.6.2-py3-none-any.whl (332 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 112 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 122 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 133 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 143 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 153 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 163 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 174 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 184 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 194 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 204 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 215 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 225 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 235 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 245 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 256 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 266 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 276 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 286 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 296 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 307 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 317 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 327 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 332 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics<0.7) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics<0.7) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics<0.7) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics<0.7) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics<0.7) (3.0.7)\n",
            "Installing collected packages: torchmetrics\n",
            "  Attempting uninstall: torchmetrics\n",
            "    Found existing installation: torchmetrics 0.7.3\n",
            "    Uninstalling torchmetrics-0.7.3:\n",
            "      Successfully uninstalled torchmetrics-0.7.3\n",
            "Successfully installed torchmetrics-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDbi0Qz4zRyG",
        "outputId": "67d6de55-f51d-4a22-a459-decea143290f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 31.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=cde3cad6e666b5a3a4975a38a7e672558d8930e4d14398deb19948cd768d0ae0\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing gpu prescence\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "qZLuOxkKLx9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64708fe3-c859-4268-9b76-d50a3339d6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import itertools\n",
        "import json\n",
        "import srsly\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "#pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertTokenizerFast as BertTokenizer, AutoModelForTokenClassification as AMTC, AdamW as Adam\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "#padding sequences\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#pytorch scheduler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "#pytorch lightning - lots of features like model checkpoints, logging, metrics, etc\n",
        "import pytorch_lightning as pl\n",
        "#checkpointing and saving models\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "#from torchmetrics import Accuracy\n",
        "from torchmetrics.functional import auroc \n",
        "#going to create a confusion matrix\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "#f1-score\n",
        "from seqeval.metrics import f1_score"
      ],
      "metadata": {
        "id": "NJbkHeunLMdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ],
      "metadata": {
        "id": "7-1qAbKJlLsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d2632c-6b60-48e5-85d1-c61d244f4a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "project_folder = \"gdrive/MyDrive/Sanah/Data\"\n",
        "os.chdir(project_folder)"
      ],
      "metadata": {
        "id": "54dN9MqcJ2WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYstxfP2OkN4",
        "outputId": "ee8738b9-75f4-4af0-b169-7b502bc2b5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints  ner_drug_disease_poster.jsonl  taggedData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxlu4nm5O8D-",
        "outputId": "856ef288-5dc0-453a-bf86-e80680fa474d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (4.1.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.4.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines as jl\n",
        "file_name = \"ner_drug_disease_poster.jsonl\"\n",
        "spanData = []\n",
        "with jl.open(file_name) as reader:\n",
        "    for obj in reader:\n",
        "      for key in list(obj.keys()):\n",
        "        if key[0] == \"_\":\n",
        "          obj.pop(key, None)\n",
        "        spanData.append(obj)\n",
        "      \n",
        "#print(spanData[0]['text'])     "
      ],
      "metadata": {
        "id": "Z3x8u1SEK4SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of spans collected\n",
        "print(\"Training data shape:\", len(spanData))\n",
        "trainingDataSize = len(spanData)"
      ],
      "metadata": {
        "id": "qqA9A59xMC4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d836dc3-437d-4946-e529-7948cf3c4afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: 5786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We will limit our sequence length to 75 tokens and we will use a batch size of 32 as suggested by the Bert paper.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7_HHNuVXwOSD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "927ebc58-248f-4223-95e5-70f3f874317c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWe will limit our sequence length to 75 tokens and we will use a batch size of 32 as suggested by the Bert paper.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH =  75#@param {type: \"integer\"}\n",
        "task = \"ner\"\n",
        "MODEL = \"allenai/scibert_scivocab_uncased\" \n",
        "OUTPUT_DIR = \"bert-ner\" #@param [\"bert-ner\"]\n",
        "BATCH_SIZE = 32 #@param {type: \"integer\"}\n",
        "NUM_EPOCHS = 3 #@param {type: \"integer\"}\n",
        "SAVE_STEPS = 100 #@param {type: \"integer\"}\n",
        "LOGGING_STEPS = 100 #@param {type: \"integer\"}\n",
        "SEED = 42 #@param {type: \"integer\"}"
      ],
      "metadata": {
        "id": "QuDIL1AYv7CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n"
      ],
      "metadata": {
        "id": "9TMH9uVLvf4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "4bc01dc4dbb14e42b75b9b4ca9958dde",
            "9d9d569dc06d47fb9338d5bfbc7519f2",
            "c071788fc1d34772a37f70a32cc2ba4f",
            "4a124102ff0e400b8f6946855f3c1e79",
            "4a2b4a4dcc7b49d98ee83e17592ce3db",
            "86bc495937eb418ca400f4a11127b72d",
            "0da097b99f35438ea6a45452a61b6fc2",
            "50e3e0ad3b4d4fb791d57b043bc74c33",
            "6f94ac64dfa8486799043b68c6849c7d",
            "472257d6a7dd4a87822d0461a29d891e",
            "0e9bb69d78d44825bf4ed012f7660b68",
            "ae31a6e0895b4f2ea6cdc58b5522f9ed",
            "78b08f8b56834207acb4c488f82802bf",
            "7069bb568786420aa128d0166687c5fe",
            "d27cd5f792a0454da845636f04a9d9ed",
            "1158c085523d4de4941e2c338b2395a6",
            "9a6cb58292e24175a768cdfc87bd19d5",
            "97c61e05d9c841fdb421bc64c5c9ff85",
            "7760a69dacab4d6ab28dbfd721371297",
            "ed77830242b94f3fa0ea65f7e6acdcde",
            "b1fd6b886c394094bba28ea647ea82ad",
            "0052db101067490c9b746c2025f3a6a6"
          ]
        },
        "outputId": "611c0df0-9cd0-4767-efe3-189f552ccfe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bc01dc4dbb14e42b75b9b4ca9958dde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/228k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae31a6e0895b4f2ea6cdc58b5522f9ed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "tokens_and_ner_tag = []\n",
        "LABELS = []\n",
        "POS_TAGS = []\n",
        "\n",
        "for obj in spanData:\n",
        "  tokens = obj[\"tokens\"]\n",
        "  spans = obj[\"spans\"]\n",
        "  for tok in tokens:\n",
        "    filter_search = [spanDict['label'] for spanDict in spans if int(spanDict['token_start']) <= int(tok['id']) <= int(spanDict['token_end'])]\n",
        "    if len(filter_search) > 0:\n",
        "      tok['label'] = (filter_search[0])\n",
        "    else:\n",
        "      tok['label'] = \"O\"\n",
        "    #extracting the pos tag\n",
        "    tok['pos'] = nltk.pos_tag([tok['text']])[0][1]\n",
        "    if tok['label'] not in LABELS:\n",
        "      LABELS.append(tok['label'])\n",
        "    if tok['pos'] not in POS_TAGS:\n",
        "      POS_TAGS.append(tok['pos'])\n",
        "#chunkify and add to tokens_and_ner_tag\n",
        "#NEW ADDITION: IOB SCHEME for chunk breakdown\n",
        "for obj in spanData:\n",
        "  tokens = obj[\"tokens\"]\n",
        "  prevTag = None\n",
        "  currTag = None\n",
        "  currTok = None\n",
        "  for tok in tokens:\n",
        "    currTag = tok['label']\n",
        "    if currTag in [\"DRUG\", \"DISEASE\"]:\n",
        "      if currTag == prevTag:\n",
        "        if \"startChunk\" not in currTok.keys():\n",
        "          currTok['label'] = \"B-\" + currTag\n",
        "          currTok['startChunk'] = True\n",
        "        tok['label'] = \"I-\"+currTag\n",
        "        #currTok['text'] += \" \" + tok['text']\n",
        "        #tok['delete'] = True\n",
        "      else:\n",
        "        currTok = tok\n",
        "        prevTag = currTag\n",
        "    else:\n",
        "      currTok = tok\n",
        "      prevTag = currTag\n",
        "\n",
        "for i,obj in enumerate(spanData):\n",
        "  tokens = obj[\"tokens\"]\n",
        "  new_tokens = []\n",
        "  for tok in tokens:\n",
        "    tok_dict_new = {}\n",
        "    if 'delete' not in tok:\n",
        "      tok_dict_new['text_id'] = str(i)\n",
        "      tok_dict_new['text'] = tok['text']\n",
        "      tok_dict_new['label'] = tok['label']\n",
        "      tok_dict_new['pos'] = tok['pos']\n",
        "      new_tokens.append(tok_dict_new)\n",
        "  tokens_and_ner_tag.append(new_tokens)\n",
        "\n",
        "\"\"\"\n",
        "we could also try and work from the sentence-level\n",
        "for sent in nltk.sent_tokenize(sentence):\n",
        "  for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "     if hasattr(chunk, 'label'):\n",
        "        print(chunk.label(), ' '.join(c[0] for c in chunk))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZvkAlFSZuVkJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "255a4ebd-d273-4445-dcf4-2b3c1d8e95fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nwe could also try and work from the sentence-level\\nfor sent in nltk.sent_tokenize(sentence):\\n  for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\\n     if hasattr(chunk, 'label'):\\n        print(chunk.label(), ' '.join(c[0] for c in chunk))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens_and_ner_tag[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyCLH8BYtt1i",
        "outputId": "77002852-e242-499f-a458-4cd1dac8ecba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text_id': '2', 'text': '1', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Turin', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Turin', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Italy', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '2', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Fondazione', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'IRCCS', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Ca', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': '’', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Granda', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Policlinico', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Hospital', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Milan', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Milan', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Italy', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '3', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'College', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'London', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'College', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'London', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Hospitals', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'London', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'UK', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '4', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Imagine', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Institute', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'INSERM', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'U1163', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Paris', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Paris', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'France', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '5', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Department', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Hematology', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Necker', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Hospital', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Assistance', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Publique', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': '-', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': 'Hôpitaux', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'de', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': 'Paris', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Paris', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'France', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '6', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Division', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Medical', 'label': 'O', 'pos': 'JJ'}, {'text_id': '2', 'text': 'Oncology', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'and', 'label': 'O', 'pos': 'CC'}, {'text_id': '2', 'text': 'Hematology', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Department', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Medicine', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Health', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Network', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Division', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Hematology', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Department', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Medicine', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Toronto', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Toronto', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'ON', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Canada', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '7', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Children', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': '’s', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Center', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'for', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Cancer', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'and', 'label': 'O', 'pos': 'CC'}, {'text_id': '2', 'text': 'Blood', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Diseases', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Children', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': '’s', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Hospital', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Los', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Angeles', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Los', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Angeles', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'CA', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'USA', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '8', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'USC', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Keck', 'label': 'O', 'pos': 'VB'}, {'text_id': '2', 'text': 'School', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Medicine', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Los', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Angeles', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'CA', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'USA', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '9', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'First', 'label': 'O', 'pos': 'RB'}, {'text_id': '2', 'text': 'Department', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Pediatrics', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'National', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'and', 'label': 'O', 'pos': 'CC'}, {'text_id': '2', 'text': 'Kapodistrian', 'label': 'O', 'pos': 'JJ'}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Athens', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Athens', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Greece', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '10', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Department', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Haematology', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Whittington', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Health', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'NHS', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Trust', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'London', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'UK', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '11', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Farhat', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Hached', 'label': 'O', 'pos': 'VBN'}, {'text_id': '2', 'text': 'Teaching', 'label': 'O', 'pos': 'VBG'}, {'text_id': '2', 'text': 'Hospital', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Sousse', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Sousse', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Tunisia', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '12', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Department', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Pediatric', 'label': 'O', 'pos': 'JJ'}, {'text_id': '2', 'text': 'Hematology', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'and', 'label': 'O', 'pos': 'CC'}, {'text_id': '2', 'text': 'Oncology', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Ege', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Hospital', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Izmir', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Turkey', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '13', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Bristol', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Myers', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': 'Squibb', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Princeton', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'NJ', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'USA', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '14', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Celgene', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'International', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Sàrl', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'a', 'label': 'O', 'pos': 'DT'}, {'text_id': '2', 'text': 'Bristol', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': '-', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': 'Myers', 'label': 'O', 'pos': 'NNS'}, {'text_id': '2', 'text': 'Squibb', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Company', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Boudry', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Switzerland', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ';', 'label': 'O', 'pos': ':'}, {'text_id': '2', 'text': '15', 'label': 'O', 'pos': 'CD'}, {'text_id': '2', 'text': 'Department', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Internal', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'Medicine', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'American', 'label': 'O', 'pos': 'JJ'}, {'text_id': '2', 'text': 'University', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': 'of', 'label': 'O', 'pos': 'IN'}, {'text_id': '2', 'text': 'Beirut', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': 'Medical', 'label': 'O', 'pos': 'JJ'}, {'text_id': '2', 'text': 'Center', 'label': 'O', 'pos': 'NNP'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Beirut', 'label': 'O', 'pos': 'NN'}, {'text_id': '2', 'text': ',', 'label': 'O', 'pos': ','}, {'text_id': '2', 'text': 'Lebanon', 'label': 'O', 'pos': 'NNP'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from glob import glob\n",
        "res = [f for f in glob(\"*.txt\") if \"sample\" in f ]\n",
        "print(len(res))\n",
        "for file in res:\n",
        "    os.remove(file)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hAKQBP1VAdHj",
        "outputId": "0cd3b395-46ed-404a-ad3c-85d819dfb493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom glob import glob\\nres = [f for f in glob(\"*.txt\") if \"sample\" in f ]\\nprint(len(res))\\nfor file in res:\\n    os.remove(file)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-hiXz7WB_IF",
        "outputId": "061d92c5-8351-4e5c-fe3f-6c1824955618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints  ner_drug_disease_poster.jsonl  taggedData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving my data in a special folder\n",
        "\"\"\"\n",
        "trainPath = \"./taggedData/\"\n",
        "os.mkdir(trainPath)\n",
        "root_file_name = \"sample\"\n",
        "for i, row in enumerate(tokens_and_ner_tag):\n",
        "  with open(trainPath + root_file_name + str(i) + '.txt', 'w') as f:\n",
        "    for tok_dict in row:\n",
        "      f.write(tok_dict['text_id'] + \", \" + tok_dict['text'] + \", \" + tok_dict['pos'] + \", \" + tok_dict['label'])\n",
        "      f.write(\"\\n\")\n",
        "    f.close()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uuNgw6U0y4J2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c7375101-65c1-4110-a808-59510b0e17e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrainPath = \"./taggedData/\"\\nos.mkdir(trainPath)\\nroot_file_name = \"sample\"\\nfor i, row in enumerate(tokens_and_ner_tag):\\n  with open(trainPath + root_file_name + str(i) + \\'.txt\\', \\'w\\') as f:\\n    for tok_dict in row:\\n      f.write(tok_dict[\\'text_id\\'] + \", \" + tok_dict[\\'text\\'] + \", \" + tok_dict[\\'pos\\'] + \", \" + tok_dict[\\'label\\'])\\n      f.write(\"\\n\")\\n    f.close()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainPath = \"./taggedData/\""
      ],
      "metadata": {
        "id": "YVkrj0Axp4nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS.extend([\"B-DISEASE\", \"I-DISEASE\", \"B-DRUG\", \"I-DRUG\"])\n",
        "#adding a padding label for both the ner labels and pos tags\n",
        "LABELS.append(\"PAD\")\n",
        "POS_TAGS.append(\"PAD\")\n",
        "\n",
        "#ner tag and pos tag encodings\n",
        "label_encoding_dict = {t: i for i, t in enumerate(LABELS)}\n",
        "pos_encoding_dict = {t: i for i, t in enumerate(POS_TAGS)}"
      ],
      "metadata": {
        "id": "xu1DZ6FtJrrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make dataset into this schema\n",
        "\n",
        "def get_all_tokens_and_ner_tags(directory):\n",
        "    pdFrames = [get_tokens_and_ner_tags(os.path.join(directory, filename)) for filename in os.listdir(directory) if filename.startswith(\"sample\")]\n",
        "    return pd.concat(pdFrames).reset_index().drop('index', axis=1)\n",
        "    \n",
        "def get_tokens_and_ner_tags(filename):\n",
        "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
        "        lines = f.readlines()\n",
        "        split_list = [list(y) for x, y in itertools.groupby(lines, lambda z: z == '\\n') if not x]\n",
        "        text_ids = list(np.concatenate([[x.split(',')[0] for x in y] for y in split_list]).flat)\n",
        "        tokens = list(np.concatenate([[x.split(',')[1] for x in y] for y in split_list]).flat)\n",
        "        pos = list(np.concatenate([[x.split(',')[2] for x in y] for y in split_list]).flat)\n",
        "        entities = list(np.concatenate([[x.split(',')[3].strip() for x in y] for y in split_list]).flat)\n",
        "    mFrame =  pd.DataFrame({\"sent_ids\": text_ids, 'tokens': tokens, \"pos\": pos, 'ner_tags': entities})\n",
        "    return mFrame\n",
        "  \n",
        "  \n",
        "def get_med_token_dataset(train_directory):\n",
        "    train_df = get_all_tokens_and_ner_tags(train_directory)\n",
        "    return (train_df)\n",
        "\n",
        "train_dataset = get_med_token_dataset(trainPath)\n",
        "print(len(train_dataset))\n"
      ],
      "metadata": {
        "id": "0AuBrKHXriK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc75d8d-4304-438c-c585-0cad1cbc6251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.drop_duplicates()\n",
        "train_dataset = train_dataset.dropna()"
      ],
      "metadata": {
        "id": "DyTnRRmp6A2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "uUssBL0hgo1W",
        "outputId": "18ea9a17-9231-4ec9-ef5e-babe5c33d4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sent_ids       tokens  pos ner_tags\n",
              "0      4786            2   CD        O\n",
              "1      4786            :    :        O\n",
              "2      4786     Electron   NN        O\n",
              "3      4786   Microscopy   NN        O\n",
              "4      4786          and   CC        O\n",
              "5      4786    gingipain   NN        O\n",
              "6      4786     presence   NN        O\n",
              "8      4786     activity   NN        O\n",
              "9      4786           on   IN        O\n",
              "10     4786         OMVs   NN        O\n",
              "11     4787            2   CD        O\n",
              "12     4787            :    :        O\n",
              "13     4787     Electron   NN        O\n",
              "14     4787   Microscopy   NN        O\n",
              "15     4787          and   CC        O\n",
              "16     4787    gingipain   NN        O\n",
              "17     4787     presence   NN        O\n",
              "19     4787     activity   NN        O\n",
              "20     4787           on   IN        O\n",
              "21     4787         OMVs   NN        O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-780b1a6d-648d-44d1-8359-e01a2db66cbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_ids</th>\n",
              "      <th>tokens</th>\n",
              "      <th>pos</th>\n",
              "      <th>ner_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4786</td>\n",
              "      <td>2</td>\n",
              "      <td>CD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4786</td>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4786</td>\n",
              "      <td>Electron</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4786</td>\n",
              "      <td>Microscopy</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4786</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4786</td>\n",
              "      <td>gingipain</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4786</td>\n",
              "      <td>presence</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4786</td>\n",
              "      <td>activity</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4786</td>\n",
              "      <td>on</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4786</td>\n",
              "      <td>OMVs</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4787</td>\n",
              "      <td>2</td>\n",
              "      <td>CD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4787</td>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4787</td>\n",
              "      <td>Electron</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4787</td>\n",
              "      <td>Microscopy</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4787</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4787</td>\n",
              "      <td>gingipain</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4787</td>\n",
              "      <td>presence</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4787</td>\n",
              "      <td>activity</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>4787</td>\n",
              "      <td>on</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4787</td>\n",
              "      <td>OMVs</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-780b1a6d-648d-44d1-8359-e01a2db66cbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-780b1a6d-648d-44d1-8359-e01a2db66cbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-780b1a6d-648d-44d1-8359-e01a2db66cbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[\"ner_tags\"].values"
      ],
      "metadata": {
        "id": "FzzCovrNk6Km",
        "outputId": "6ab50e3e-af6f-438f-b37c-99c0da88f94d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'O', 'O', ..., 'O', 'O', 'O'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "traindf, valdf = train_test_split(train_dataset, test_size=0.2)\n",
        "traindf.shape, valdf.shape\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "s8KtYRb4VUAp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5bc52f0-b801-41df-d90f-b4ddb7c1a076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.model_selection import train_test_split\\ntraindf, valdf = train_test_split(train_dataset, test_size=0.2)\\ntraindf.shape, valdf.shape\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer Pipeline"
      ],
      "metadata": {
        "id": "nYI_qExdhFZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Quick Modeling"
      ],
      "metadata": {
        "id": "DZgegTWWxzVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceGetter(object):\n",
        "    def __init__(self, data):\n",
        "        self.num_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "       # agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "       #                                                    s[\"POS\"].values.tolist(),\n",
        "        #                                                   s[\"Tag\"].values.tolist())]\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"tokens\"].values.tolist(), s[\"pos\"].values.tolist(),\n",
        "                                                           s[\"ner_tags\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"sent_ids\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"{}\".format(self.num_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "metadata": {
        "id": "0ZRZ3cjFQQ5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getter = SentenceGetter(train_dataset)"
      ],
      "metadata": {
        "id": "oEdAkFWIQcHy",
        "outputId": "8fb9e2f4-b0e9-4bce-8d8f-11640c2ded32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-306640aee1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceGetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\n",
        "pos_tags = [[s[1] for s in sentence] for sentence in getter.sentences]\n",
        "ner_tags = [[s[2] for s in sentence] for sentence in getter.sentences]"
      ],
      "metadata": {
        "id": "M5F8ngWIQ_tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization function\n",
        "def tokenize_and_align_labels(examples, pos_t, ner_tags):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "    pos_tags = []\n",
        "    for word, pos, label in zip(examples,pos_t, ner_tags):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        #Add the same pos tag to the new list of pos_tags `n_subwords` times\n",
        "        pos_tags.extend([pos]*n_subwords)\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, pos_tags, labels"
      ],
      "metadata": {
        "id": "coG3nfMnKW7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_and_labels = [\n",
        "    tokenize_and_align_labels(sent,p_tags, n_tags)\n",
        "    for sent, p_tags, n_tags in zip(sentences, pos_tags, ner_tags)\n",
        "]"
      ],
      "metadata": {
        "id": "7RT5bLooQdHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_final = [token_label_triple[0] for token_label_triple in tokenized_texts_and_labels]\n",
        "pos_tags_final = [token_label_triple[1] for token_label_triple in tokenized_texts_and_labels]\n",
        "labels = [token_label_triple[2] for token_label_triple in tokenized_texts_and_labels]\n"
      ],
      "metadata": {
        "id": "RbrH3xacdTtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenized_texts_final))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "id": "7S81xIszeTpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cut and pad to the desied length 75 bcz ab no of token increase ho gya\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_final],\n",
        "                          maxlen=MAX_LENGTH, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "8pfcpXXsdkMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoding_dict.keys()"
      ],
      "metadata": {
        "id": "6mTAh2OHf_Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags = pad_sequences([[label_encoding_dict[\"O\"] if l not in label_encoding_dict else label_encoding_dict.get(l) for l in lab] for lab in labels], maxlen=MAX_LENGTH, dtype=\"long\", value=label_encoding_dict[\"PAD\"],\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "PPGogWSydnLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attenation mask to ignore PAD token\n",
        "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
      ],
      "metadata": {
        "id": "Y8DQDr-5dtHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10per train and validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "\"\"\"\n",
        "input_ids = [sent_dict[\"input_ids\"] for sent_dict in tokenized_texts_and_labels]\n",
        "tags = [sent_dict[\"labels\"] for sent_dict in tokenized_texts_and_labels]\n",
        "attention_masks = [sent_dict[\"attention_mask\"] for sent_dict in tokenized_texts_and_labels]\n",
        "\"\"\"\n",
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n",
        "                                                            random_state=2022, test_size=0.1)\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2022, test_size=0.1)"
      ],
      "metadata": {
        "id": "4j0IZLmnPYvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to torch tensors\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "metadata": {
        "id": "cdaXxVuKxxff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training time shuffling of the data and testing time we pass them sequentially\n",
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "vn3zA2bsyDFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load a pre-trained BERT model - transfer learning\n",
        "bert_model = AMTC.from_pretrained(MODEL, return_dict=True)"
      ],
      "metadata": {
        "id": "wzAidpv2yGJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "xrq02DeOe9Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classifier layer\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "     def __init__(self, input_dim, output_dim):\n",
        "         super(LogisticRegression, self).__init__()\n",
        "         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "     def forward(self, x):\n",
        "         outputs = torch.sigmoid(self.linear(x))\n",
        "         return outputs"
      ],
      "metadata": {
        "id": "5u8z3LE5fZjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "RjdpF_v8Aa75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "P94ncTJ4AtOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "model = AMTC.from_pretrained(model_checkpoint, num_labels=len(LABELS))\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"test-{task}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=1e-5,\n",
        ")\n",
        "\n",
        "#data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [[LABELS[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
        "    true_labels = [[LABELS[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\"precision\": results[\"overall_precision\"], \"recall\": results[\"overall_recall\"], \"f1\": results[\"overall_f1\"], \"accuracy\": results[\"overall_accuracy\"]}\n",
        "    \n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=valid_data,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "trainer.save_model('drug-disease-ner.model')"
      ],
      "metadata": {
        "id": "5X2SS-aMhEjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForTokenClassification\n",
        "bert_model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=len(LABELS),\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")"
      ],
      "metadata": {
        "id": "1VHBmbxggwal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device\n",
        "device = \"cpu\"\n",
        "ON_CPU = True\n",
        "if ON_CPU:\n",
        "  device = \"cpu\"\n",
        "else:\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "DWwP0UCgUkxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#push the parameters to the default device\n",
        "bert_model.to(device)"
      ],
      "metadata": {
        "id": "z-Pm-dUWyMR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(bert_model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(bert_model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = Adam(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "metadata": {
        "id": "BpKjzGjcyQGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * NUM_EPOCHS\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "USj63vUmy-2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "lg7wsg0EWDNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "rOyMmoYbYJIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "bQ24ldM_ZL-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Store the average loss after each epoch so we can plot them.\n",
        "train_loss_values, validation_loss_values = [], []\n",
        "\n",
        "for _ in tqdm(range(NUM_EPOCHS)):\n",
        "    bert_model.zero_grad()\n",
        "    # Put the model into training mode.\n",
        "    bert_model.train()\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Training loop\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Before Back pass - clear grads\n",
        "        bert_model.zero_grad()\n",
        "\n",
        "        #DOES NOT LOOK LIKE A DIMENSION ERROR HERE\n",
        "        print(len(b_input_ids))\n",
        "        print(len(b_labels))\n",
        "\n",
        "        # forward pass\n",
        "        # This will return the loss (rather than the model output)\n",
        "        # because we have provided the `labels`.\n",
        "        output = bert_model(b_input_ids, attention_mask=b_input_mask)\n",
        "        classifier = LogisticRegression(bert_model.config.hidden_size, len(LABELS)-1)\n",
        "        output = classifier(output.pooler_output)\n",
        "        #our activation function\n",
        "        output = torch.sigmoid(output)    \n",
        "        loss = 0\n",
        "        if b_labels is not None:\n",
        "            loss = criterion(output, b_labels)\n",
        "        #loss\n",
        "        #loss = outputs[0]\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        total_loss += loss.item()\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "\n",
        "    train_loss_values.append(avg_train_loss)\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "id": "VlIOLPEzy_bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch Lightning"
      ],
      "metadata": {
        "id": "dtAxIRnSxqcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        " tokenized_inputs = tokenizer.encode_plus(list(examples[\"tokens\"]), truncation=True, is_split_into_words=True, max_length=MAX_LENGTH,\n",
        "      return_token_type_ids=False,\n",
        "      padding=\"max_length\",\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt')\n",
        "    labels_t = []\n",
        "    pos_t = []\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif label[word_idx] == '0':\n",
        "                label_ids.append(0)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label_encoding_dict[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(label_encoding_dict[label[word_idx]] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels_t.append(label_ids)\n",
        "    for i, pos in enumerate(examples[\"pos\"]):\n",
        "        words_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        pos_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                pos_ids.append(-100)\n",
        "            elif label[word_idx] == '0':\n",
        "                pos_ids.append(0)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                pos_ids.append(pos_encoding_dict[pos[word_idx]])\n",
        "            else:\n",
        "                pos_ids.append(pos_encoding_dict[pos[word_idx]] if pos_all_tokens else -100)\n",
        "            previous_word_idx = word_idx    \n",
        "        pos_t.append(pos_ids)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RDMMVQjWE_zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a pytorch dataset class\n",
        "class MedicalDataset(Dataset):\n",
        "  def __init__(self, data, tokenizer):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.dataLen = len(self.data)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.dataLen\n",
        "\n",
        "  def tokenize_and_align_labels(self, examples):\n",
        "    label_all_tokens = True\n",
        "    pos_all_tokens = True\n",
        "\n",
        "    tokenized_inputs = tokenizer.encode_plus(list(examples[\"tokens\"]), truncation=True, is_split_into_words=True, max_length=MAX_LENGTH,\n",
        "      return_token_type_ids=False,\n",
        "      padding=\"max_length\",\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt')\n",
        "    \n",
        "    labels = list(examples[\"tokens\"])\n",
        "    pos = list(examples[\"pos\"])\n",
        "\n",
        "    labels_t = pad_sequences([label_encoding_dict.get(lab) for lab in labels],\n",
        "                     maxlen=MAX_LENGTH, value=label_encoding_dict[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "    \n",
        "    pos_t = pad_sequences([pos_encoding_dict.get(pt) for pt in pos],\n",
        "                     maxlen=MAX_LENGTH, value=pos_encoding_dict[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "    return dict(\n",
        "      input_ids=tokenized_inputs[\"input_ids\"].flatten(),\n",
        "      attention_mask=tokenized_inputs[\"attention_mask\"].flatten(),\n",
        "      pos = torch.FloatTensor(pos_t),\n",
        "      labels=torch.FloatTensor(labels_t)\n",
        "    )\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    data_rows = self.data[self.data['sent_ids'] == i]\n",
        "    return self.tokenize_and_align_labels(data_rows)"
      ],
      "metadata": {
        "id": "viuR778bVa1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalTextDataModule(pl.LightningDataModule):\n",
        "  #three datasets - training, testing, validation dataset\n",
        "  def __init__(self, train_df, val_df, test_df, tokenizer):\n",
        "    super().__init__()\n",
        "    self.train_df = train_df\n",
        "    self.test_df = test_df\n",
        "    self.val_df = val_df\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  #datasets setup - training, validation, testing  \n",
        "  def setup(self, stage=None):\n",
        "    self.train_dataset = MedicalDataset(\n",
        "      self.train_df,\n",
        "      self.tokenizer\n",
        "    )\n",
        "    self.val_dataset = MedicalDataset(\n",
        "        self.val_df, \n",
        "        self.tokenizer)\n",
        "    \n",
        "    self.test_dataset = MedicalDataset(\n",
        "      self.test_df,\n",
        "      self.tokenizer\n",
        "    )\n",
        "\n",
        "  #The num_workers attribute tells the data loader instance how many sub-processes to use for data loading.\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.train_dataset,\n",
        "      batch_size= BATCH_SIZE,\n",
        "      shuffle=True,\n",
        "      num_workers=2)\n",
        "    \n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.val_dataset,\n",
        "      batch_size= BATCH_SIZE,\n",
        "      shuffle=False,\n",
        "      num_workers=2)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.test_dataset,\n",
        "      batch_size=BATCH_SIZE,\n",
        "      num_workers=2)"
      ],
      "metadata": {
        "id": "l_LrggvZVeuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load a pre-trained BERT model - transfer learning\n",
        "bert_model = AMTC.from_pretrained(MODEL, return_dict=True)"
      ],
      "metadata": {
        "id": "B2VPV7lCVffO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalTextLabelClassifier(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, bert_model, n_classes, criterion, n_training_steps=None):\n",
        "    super().__init__()\n",
        "    #pre-trained bert_model\n",
        "    self.bert = bert_model\n",
        "    #top logistic regression layer\n",
        "    self.classifier = LogisticRegression(self.bert.config.hidden_size, n_classes)\n",
        "    #how many times step is called\n",
        "    self.n_training_steps = n_training_steps\n",
        "    self.criterion = criterion\n",
        "\n",
        "  #the forward function enables us to define how the model goes from input to output\n",
        "  def forward(self, input_ids, attention_mask, labels=None):\n",
        "    #reset the weights before backward pass\n",
        "    self.bert.zero_grad()\n",
        "    output = self.bert(input_ids, attention_mask=attention_mask, labels = labels)\n",
        "    #last layer to a classifier output\n",
        "    #output = self.classifier(output.pooler_output)\n",
        "    #our activation function\n",
        "    output = torch.sigmoid(output)    \n",
        "    loss = 0\n",
        "    if labels is not None:\n",
        "        loss = self.criterion(output, labels)\n",
        "    return loss, output\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    #attention masks - binary masks to hide the padded indices\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    if batch_idx % 5000:\n",
        "      print({\"loss\": loss})\n",
        "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    return loss\n",
        "\n",
        "  def training_epoch_end(self, outputs):\n",
        "    #collecting the labels and predictions from the output\n",
        "    labels = []\n",
        "    predictions = []\n",
        "    for output in outputs:\n",
        "      for output_labels in output[\"labels\"].detach().cpu():\n",
        "        labels.append(output_labels)\n",
        "      for output_predictions in output[\"predictions\"].detach().cpu():\n",
        "        predictions.append(output_predictions)\n",
        "\n",
        "    labels = torch.stack(labels).int()\n",
        "    predictions = torch.stack(predictions)\n",
        "\n",
        "  def config_params(self, fineTune=False):\n",
        "    if fineTune:\n",
        "      param_optimizer = list(self.bert.named_parameters())\n",
        "      no_decay = ['bias', 'gamma', 'beta']\n",
        "      optimizer_grouped_parameters = [\n",
        "          {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "          'weight_decay_rate': 0.01},\n",
        "          {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "          'weight_decay_rate': 0.0}\n",
        "      ]\n",
        "    else:\n",
        "        param_optimizer = list(self.bert.named_parameters())\n",
        "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "    return optimizer_grouped_parameters\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    opt_params = self.config_params(True)\n",
        "\n",
        "    optimizer = Adam(opt_params, lr=1e-5)\n",
        "\n",
        "    #the scheduler enables us to adjust the learning rate\n",
        "    scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "    return dict(\n",
        "      optimizer=optimizer,\n",
        "      lr_scheduler=dict(\n",
        "        scheduler=scheduler,\n",
        "        interval='step'\n",
        "      )\n",
        "    )"
      ],
      "metadata": {
        "id": "Pzx1pWnlVlhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criterion - measuring the Binary Cross Entropy between the target and the input probabilities\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "QeMJpjLSqcqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "#calculating number of train steps\n",
        "total_training_steps = BATCH_SIZE * NUM_EPOCHS\n",
        "\n",
        "model = MedicalTextLabelClassifier(\n",
        "    bert_model,\n",
        "  n_classes=len(LABELS)-1,\n",
        "  criterion = criterion,\n",
        "  n_training_steps=total_training_steps\n",
        ")\n",
        "\n",
        "#checkpointing and saving\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filename=\"sample-NER-{epoch:02d}-{val_loss:.2f}\",\n",
        "    save_top_k=2,\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "\n",
        "#lightning module training configs\n",
        "trainer = pl.Trainer(\n",
        "  logger= None,\n",
        "  checkpoint_callback= None,\n",
        "  callbacks= None,\n",
        "  gpus=1,\n",
        "  max_epochs=NUM_EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "aBDG7YxcWb5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a data module with all datasets in place\n",
        "med_data_module = MedicalTextDataModule(traindf, valdf, valdf, tokenizer)"
      ],
      "metadata": {
        "id": "1FbxhQ05Wwrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting \n",
        "trainer.fit(model, med_data_module)"
      ],
      "metadata": {
        "id": "jZnXvL_fwC7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation mode\n",
        "model.eval()\n",
        "model.freeze()"
      ],
      "metadata": {
        "id": "LInIxbMJXEXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "trained_model = model.to(device)\n",
        "#evaluation\n",
        "val_dataset = MedicalDataset(valdf, tokenizer)\n",
        "\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "#wrap the iterable with tqdm\n",
        "for item in tqdm(val_dataset):\n",
        "  _, prediction = trained_model(\n",
        "    item[\"input_ids\"].unsqueeze(dim=0).to(device), \n",
        "    item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
        "  )\n",
        "  predictions.append(prediction.flatten())\n",
        "  labels.append(item[\"labels\"].int())\n",
        "\n",
        "predictions = torch.stack(predictions).detach().cpu()\n",
        "labels = torch.stack(labels).detach().cpu()"
      ],
      "metadata": {
        "id": "3qenvdULpy00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CUTOFF = 0.5\n",
        "#fscore, precision, recall, etc\n",
        "y_pred = predictions.numpy()\n",
        "\n",
        "#true labels, vs predictions - assigned an upper and lower bound\n",
        "y_true = labels.numpy()\n",
        "y_pred = np.where(y_pred >= CUTOFF, 1, 0)\n"
      ],
      "metadata": {
        "id": "LUN9cMY5XIJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(y_true, y_pred)"
      ],
      "metadata": {
        "id": "E5yu3qIopyAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSavedModel(path):\n",
        "  model = MedicalTextLabelClassifier.load_from_checkpoint(path)\n",
        "  model.eval()\n",
        "  return model"
      ],
      "metadata": {
        "id": "QVWj5e_ajK-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}